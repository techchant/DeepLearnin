{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@Author : TechCHant\\n@tensorflow-version > 2.0\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "@Author : TechCHant\n",
    "@tensorflow-version > 2.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "gpu=tf.config.experimental.list_physical_devices('GPU')\n",
    "gpu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "(train_data,train_lable),(test_data,test_lable)=imdb.load_data(num_words=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "reverse_word = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "decoded_review = ' '.join([reverse_word.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? this film was just brilliant casting location scenery story direction ? really ? the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same ? island as myself so i loved the fact there was a real ? with this film the witty ? throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the ? ? was amazing really ? at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little ? that played the ? of ? and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all ? up are such a big ? for the whole film but these children are amazing and should be ? for what they have done don't you think the whole story was so lovely because it was true and was ? life after all that was ? with us all\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body> We cannot feed a list to thge Nural Network So we are converting it to a tgensor using one hot encoder , so in the bellow function its set 1 to specific indices whre we define all zero matrix of shape len(sequences) X dimention=10000<body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# Our vectorized training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "# Our vectorized test data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we need to vectorise our lable \n",
    "\n",
    "# Our vectorized labels\n",
    "y_train = np.asarray(train_lable).astype('float32')\n",
    "y_test = np.asarray(test_lable).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body> input data is a vector and the lables are scalers (1 or 0 ) / Good or bad so for geting thsi kind of prediction we use Dense layer with relu activation function \n",
    "where 16 is the no of hidden layers \n",
    "Basic Code of ReLU :\n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "def ReLU(input):\n",
    "    if input > 0:\n",
    "        return input\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    s=1/(1+np.exp(-x))\n",
    "    ds=s*(1-s)  \n",
    "    return s,ds\n",
    "\n",
    "</body>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 0.5787 - binary_accuracy: 0.7317 - val_loss: 0.4685 - val_binary_accuracy: 0.8451\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.4032 - binary_accuracy: 0.8676 - val_loss: 0.3754 - val_binary_accuracy: 0.8547\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3266 - binary_accuracy: 0.8824 - val_loss: 0.3318 - val_binary_accuracy: 0.8663\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.2873 - binary_accuracy: 0.8898 - val_loss: 0.3095 - val_binary_accuracy: 0.8743\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2653 - binary_accuracy: 0.8979 - val_loss: 0.3051 - val_binary_accuracy: 0.8759\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2509 - binary_accuracy: 0.9025 - val_loss: 0.3251 - val_binary_accuracy: 0.8639\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2412 - binary_accuracy: 0.9049 - val_loss: 0.3085 - val_binary_accuracy: 0.8747\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2329 - binary_accuracy: 0.9097 - val_loss: 0.3105 - val_binary_accuracy: 0.8735\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2267 - binary_accuracy: 0.9123 - val_loss: 0.3160 - val_binary_accuracy: 0.8719\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2218 - binary_accuracy: 0.9127 - val_loss: 0.3631 - val_binary_accuracy: 0.8553\n",
      "Epoch 11/20\n",
      "25/30 [========================>.....] - ETA: 0s - loss: 0.2197 - binary_accuracy: 0.9112"
     ]
    }
   ],
   "source": [
    "#Restricted with GPU \n",
    "try:\n",
    "    if gpu[0]:\n",
    "        history = model.fit(partial_x_train,\n",
    "                        partial_y_train,\n",
    "                        epochs=20,\n",
    "                        batch_size=512,\n",
    "                        validation_data=(x_val, y_val))\n",
    "except Exception as e :\n",
    "    print(\"No GPU AVAILABLE \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It contains 4 entries: one per metric that was being monitored, during training and during validation. Let's use Matplotlib to plot the \n",
    "#training and validation loss side by side, as well as the training and validation accuracy:\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['binary_accuracy']\n",
    "val_acc_values = history_dict['val_binary_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "Now we can see the out come of the above tranig for eacha and every epoch the loss decrease and traning accuracy incrise , this was known as validation step .\n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='sigmoid'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#Restricted with GPU \n",
    "try:\n",
    "    if gpu[0]:\n",
    "        model.fit(x_train, y_train, epochs=40, batch_size=1024)\n",
    "        results = model.evaluate(x_test, y_test)\n",
    "except Exception as e :\n",
    "    print(\"No GPU AVAILABLE \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
